<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>fml blog</title>
    <link>https://fml-fam.github.io/blog/</link>
    <description>Recent content on fml blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.</copyright>
    <lastBuildDate>Fri, 17 Dec 2021 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://fml-fam.github.io/blog/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>My Favorite R Packages</title>
      <link>https://fml-fam.github.io/blog/2021/12/17/my-favorite-r-packages/</link>
      <pubDate>Fri, 17 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fml-fam.github.io/blog/2021/12/17/my-favorite-r-packages/</guid>
      <description>I&amp;rsquo;ll warn you right off the bat, this is going to be an unusual list. Maybe I&amp;rsquo;m just an unusual guy. For sure there are some packages here that you&amp;rsquo;ve heard of. But I&amp;rsquo;m also pretty sure that there are some you haven&amp;rsquo;t.
Most of these are packages I use on a daily basis, with a few on a weekly basis. There are a few that I don&amp;rsquo;t use that often, but I consider them categorically the best at what they do and sometimes I do those things.</description>
    </item>
    
    <item>
      <title>Computing Eigenvalues Out-of-Core</title>
      <link>https://fml-fam.github.io/blog/2021/10/25/computing-eigenvalues-out-of-core/</link>
      <pubDate>Mon, 25 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fml-fam.github.io/blog/2021/10/25/computing-eigenvalues-out-of-core/</guid>
      <description>In an earlier post, I discussed how you can compute SVD (and spectral decomposition) via Lanczos Iteration. Several times in that post, I mentioned that the method lends itself well to out-of-core data &amp;mdash; that is, data stored on disk rather than in memory. But I never bothered to actually go into any details. Recently I had the need for an out-of-core eigensolver, and I have implemented it in this R package.</description>
    </item>
    
    <item>
      <title>A Bit About Checkpoint/Restart</title>
      <link>https://fml-fam.github.io/blog/2021/09/09/a-bit-about-checkpoint/restart/</link>
      <pubDate>Thu, 09 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fml-fam.github.io/blog/2021/09/09/a-bit-about-checkpoint/restart/</guid>
      <description>Checkpoint/Restart (C/R) is a fault tolerance strategy common in high performance computing, but as far as I can tell, almost totally unknown to statistical computing. The basic idea is that you save some/all of the state from your running program in order to be able to resume it in the event that the computation is interrupted.
Maybe it&amp;rsquo;s storming outside and your power is spotty. Even if you have a laptop or a power supply, how long will that downed tree knock out your power?</description>
    </item>
    
    <item>
      <title>Matrix Computations in Constrained Memory Environments</title>
      <link>https://fml-fam.github.io/blog/2021/06/29/matrix-computations-in-constrained-memory-environments/</link>
      <pubDate>Tue, 29 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fml-fam.github.io/blog/2021/06/29/matrix-computations-in-constrained-memory-environments/</guid>
      <description>Many times in my professional career, a researcher has approached me for help performing some kind of matrix calculation that is getting &amp;ldquo;expensive&amp;rdquo; as their data grows. Sometimes the expense is in compute time: it&amp;rsquo;s just taking too long. Recently, someone approached me who didn&amp;rsquo;t care at all how long it took to compute something. Their problem was getting the thing to run within the RAM constraints in their particular computing environment, which they couldn&amp;rsquo;t really deviate from.</description>
    </item>
    
    <item>
      <title>Matrix Factorizations for Data Analysis</title>
      <link>https://fml-fam.github.io/blog/2020/07/03/matrix-factorizations-for-data-analysis/</link>
      <pubDate>Fri, 03 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://fml-fam.github.io/blog/2020/07/03/matrix-factorizations-for-data-analysis/</guid>
      <description>Integers can be factored into products of special kinds of integers with useful properties called primes. Similarly, matrices can be factored into products of special kinds of matrices with useful properties.
Because data analysis often involves operating on numeric matrices, understanding how and why to factor matrices can be very helpful. We&amp;rsquo;re going to talk about the major factorizations, namely LU, Cholesky, QR, SVD, and Eigendecomposition. There are others, but if you master these, then you&amp;rsquo;re off to a great start.</description>
    </item>
    
    <item>
      <title>Vignette-less Articles With pkgdown</title>
      <link>https://fml-fam.github.io/blog/2020/06/23/vignette-less-articles-with-pkgdown/</link>
      <pubDate>Tue, 23 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://fml-fam.github.io/blog/2020/06/23/vignette-less-articles-with-pkgdown/</guid>
      <description>Long Boring Background You Can Skip I don&amp;rsquo;t like the R vignette system. At its core, it&amp;rsquo;s a good idea. Having long-form package documentation is a good thing, and having the ability to put in source code listings that get automatically executed during rebuilds is great. But the way it works in practice is, to me, extremely annoying. Whenever you build/test your package, the vignettes will automatically be rebuilt, even if that&amp;rsquo;s not what you want.</description>
    </item>
    
    <item>
      <title>Introducing fml - the Fused Matrix Library</title>
      <link>https://fml-fam.github.io/blog/2020/06/21/introducing-fml-the-fused-matrix-library/</link>
      <pubDate>Sun, 21 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://fml-fam.github.io/blog/2020/06/21/introducing-fml-the-fused-matrix-library/</guid>
      <description>What is fml? fml is the Fused Matrix Library, a permissively licensed, header-only C++ library for dense matrix computing. The emphasis is on real-valued matrix types (float, double, and __half) for numerical operations useful for data analysis.
The library provides 3 main classes: cpumat, gpumat, and mpimat. There is currently an experimental parmat class, but it is at present not well developed. For the main classes:
 CPU: Single node cpu computing (multi-threaded if using multi-threaded BLAS and linking with OpenMP).</description>
    </item>
    
    <item>
      <title>SVD via Lanczos Iteration</title>
      <link>https://fml-fam.github.io/blog/2020/06/15/svd-via-lanczos-iteration/</link>
      <pubDate>Mon, 15 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://fml-fam.github.io/blog/2020/06/15/svd-via-lanczos-iteration/</guid>
      <description>Background Every few years, I try to figure out the Lanczos method to approximate SVD of a rectangular matrix. Unfortunately, every resource I find always leaves out enough details to confuse me. All of the information I want is available across multiple writeups, but everyone uses different notation, making things even more confusing.
This time I finally sat down and got to a point where I finally felt like I understood it.</description>
    </item>
    
    <item>
      <title>About</title>
      <link>https://fml-fam.github.io/blog/page/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://fml-fam.github.io/blog/page/about/</guid>
      <description>This is a blog mostly dedicated to the fml project, a C++ framework with R bindings for high-performance dense matrix computing. Sometimes I also talk about math/computing things that I&amp;rsquo;m thinking about, usually in relation to fml.
I use a lot of LaTeX in posts, so enabling JavaScript for MathJax will make things look much nicer. I don&amp;rsquo;t use any kind of trackers (that I&amp;rsquo;m aware of). Currently I use GitHub Pages for hosting.</description>
    </item>
    
  </channel>
</rss>